{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s23ZFy9RVib"
      },
      "source": [
        "# Lab 4: Transfer Learning and BERT!\n",
        "\n",
        "Due on: 04/15/2024 @ 9pm\n",
        "\n",
        "Agenda\n",
        "------\n",
        "+ Get an overview of the BERT architecture\n",
        "+ Download and play with a pre-trained BERT model\n",
        "+ Train your own network that has a pre-trained BERT component\n",
        "+ Play with some parameters!\n",
        "\n",
        "\n",
        "Summary\n",
        "----\n",
        "This lab will guide you through the setup and uses of pretrained models in `Tensorflow` and `transformers`. In this lab we focus on BERT (https://github.com/google-research/bert/) an __encoder only transformer model__. We will use the pretrained model to extract features from text and use these features to train a classifier to classify different types of data. We will setup a binary classifier on the IMDB dataset. You will be working on training new models on the other datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3IwQvnSRVic"
      },
      "source": [
        "# Task 0: Who is in your group?\n",
        "\n",
        "Please work in groups of up to 3 people!\n",
        "\n",
        "Jack Arseneau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCH0a7APRVid"
      },
      "source": [
        "TASK 1: BERT questions\n",
        "---\n",
        "\n",
        "Before we dive into the code, we'd like you to take a moment to familiarize yourself with the architecture of BERT.\n",
        "\n",
        "Take a look at the following resources as a group:\n",
        "- [Illustrated BERT](http://jalammar.github.io/illustrated-bert/)\n",
        "- SLP Chapter 11.1\n",
        "- [BERT paper](https://aclanthology.org/N19-1423/)\n",
        "\n",
        "Answer the questions in the next cell about the BERT architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvKbZhpqRVid"
      },
      "source": [
        "1. What does BERT stand for?\n",
        "\n",
        " Bidirectional Encoder Representations from Transformers\n",
        "\n",
        "2. What task is the BERT pre-trained model trained on?\n",
        "\n",
        " Deep bidirectional representations of unlabeled text.\n",
        "\n",
        "3. How many parameters does BERT_{BASE} have? BERT_{LARGE}?\n",
        "\n",
        " Bert Base: (L=12, H=768, A=12, Total Parameters=110M)\n",
        "\n",
        " Bert Large: (L=24, H=1024, A=16, Total Parameters=340M)\n",
        "\n",
        "4. What is the architecture of BERT_{BASE}? (what kind of neural network is it, what are the relevant dimensionality numbers?)\n",
        "\n",
        " Multilayer bidirectional transformer encoder\n",
        "\n",
        "5. What can we feed as input to BERT?\n",
        "\n",
        " An arbitrary span of contiguous text.\n",
        "\n",
        "6. What is the output of BERT?\n",
        "\n",
        " A predicted series of embeddings starting with the [CLS] token\n",
        "\n",
        "7. If we want to use BERT to help with a classification task, what is a high-level description of what we'll do? (2 - 3 sentences.)\n",
        "\n",
        " We must first pre train the model with masked sentences, then fine tune the model to perform the task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSm3NqlhRVid"
      },
      "source": [
        "Installation Intermission\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1C-vVvT3cEj",
        "outputId": "052a6f24-1b80-45ae-f80b-8226c4f63fe9",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.14.0 in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: transformers==4.35.0 in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (0.17.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.0) (4.66.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.45.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (2024.10.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.0) (2024.8.30)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# make sure that the correct version of transformers and tensorflow is installed\n",
        "# https://huggingface.co/docs/transformers/index\n",
        "# https://www.tensorflow.org/install/pip\n",
        "!pip install tensorflow==2.14.0 transformers==4.35.0\n",
        "\n",
        "# if you are on a mac w/ an M1 chip, you'll need a specific tensorflow-metal version\n",
        "# !pip install tensorflow-metal==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "70O-tnuj3U72",
        "outputId": "1aa8d8ec-bfb1-4094-f383-df67eb78f214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# if you want, not required\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc5ROhEU3U73"
      },
      "source": [
        "Check your versions with the following code:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzyFio-l3U73",
        "outputId": "27ca4ba6-2564-4235-ea1d-6d0383e0cd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensforflow Version :  2.14.0\n",
            "Transformers Version :  4.35.0\n"
          ]
        }
      ],
      "source": [
        "# Version Info\n",
        "print(\"Tensforflow Version : \" ,tf.__version__)\n",
        "print(\"Transformers Version : \" ,transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPd9hZXtC1RB"
      },
      "source": [
        "## TASK 2: The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3R6TcHg3U74"
      },
      "source": [
        "We will be using reviews from the UCI Machine Learning Repository\n",
        "\n",
        "URL : https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
        "\n",
        "This should have three files :\n",
        "\n",
        "1. imbd_labelled.txt\n",
        "2. amazon_cells_labelled.txt\n",
        "3. yelp_labelled.txt\n",
        "\n",
        "We use the tensorflow utils to download and extract the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYulutFq3U74",
        "outputId": "683d9c5f-bddf-4fbb-978c-3fd1b8bb104c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " data/datasets/sentiment+labelled+sentences.zip\n"
          ]
        }
      ],
      "source": [
        "# make a data folder\n",
        "!mkdir -p data\n",
        "\n",
        "# download the data\n",
        "out_path = tf.keras.utils.get_file(origin=\"https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\",extract=True,cache_dir=\"data\")\n",
        "print(\"\\n\",out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUrzd6_x3U74"
      },
      "source": [
        "Let's take a peek at the data with `pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "X9vOov4r3U74",
        "outputId": "d9e8f959-acff-4f2c-8472-f5ee75add553"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0  1\n",
              "0    A very, very, very slow-moving, aimless movie ...  0\n",
              "1    Not sure who was more lost - the flat characte...  0\n",
              "2    Attempting artiness with black & white and cle...  0\n",
              "3         Very little music or anything to speak of.    0\n",
              "4    The best scene in the movie was when Gerardo i...  1\n",
              "..                                                 ... ..\n",
              "743  I just got bored watching Jessice Lange take h...  0\n",
              "744  Unfortunately, any virtue in this film's produ...  0\n",
              "745                   In a word, it is embarrassing.    0\n",
              "746                               Exceptionally bad!    0\n",
              "747  All in all its an insult to one's intelligence...  0\n",
              "\n",
              "[748 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6207d10-b31b-4c50-be7c-1e77cc78c24b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>I just got bored watching Jessice Lange take h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>In a word, it is embarrassing.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>Exceptionally bad!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>All in all its an insult to one's intelligence...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>748 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6207d10-b31b-4c50-be7c-1e77cc78c24b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6207d10-b31b-4c50-be7c-1e77cc78c24b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6207d10-b31b-4c50-be7c-1e77cc78c24b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bdf241a5-031c-4b6d-9732-54c5a5db6524\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bdf241a5-031c-4b6d-9732-54c5a5db6524')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bdf241a5-031c-4b6d-9732-54c5a5db6524 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_398ce324-68ec-42c0-8a0e-a9f99ee6950e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('imdb_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_398ce324-68ec-42c0-8a0e-a9f99ee6950e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('imdb_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "imdb_df",
              "summary": "{\n  \"name\": \"imdb_df\",\n  \"rows\": 748,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 745,\n        \"samples\": [\n          \"I couldn't take them seriously.  \",\n          \"This gets a 1 out of 10, simply because there's nothing lower.  \",\n          \"I hate movies like that.  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# viewing the data\n",
        "imdb_data = \"data/datasets/sentiment labelled sentences/imdb_labelled.txt\"\n",
        "imdb_df = pd.read_csv(imdb_data, sep=\"\\t\", header=None)\n",
        "imdb_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o12HL7Cs3U75"
      },
      "source": [
        "Models usually take batches of the same size. It would be useful to check the distribution of the lengths of the sentences in the dataset. (We will need to define a max length of sentences to use.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Emrbxhyk3U75",
        "outputId": "30fd8032-1df5-4a39-f950-4d618ff0b756"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: plot the length of the reviews\n",
        "# hint: use the .str.len() method on the first column of the dataframe to get the length of the sentences out\n",
        "# y axis should be the count/number of reviews\n",
        "# x axis should be the length of the reviews\n",
        "# a histogram is a good choice here for visualization\n",
        "# label your axes!\n",
        "\n",
        "def display_histogram(data, title=\"IMDb Reviews\"):\n",
        "    lengths = [len(review) for review in data.loc[:,0]]\n",
        "\n",
        "    x = [length for length in lengths]\n",
        "\n",
        "    plt.hist(x,bins=30)\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.xlabel(\"Review Length\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "display_histogram(imdb_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmigAhUuC4Yv"
      },
      "source": [
        "**TODO:** Explore the other two data files, similarly to what we have done above (and what we've done on our homeworks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IMGFRmnWDBEu",
        "outputId": "a2f8c19f-e749-46fa-a9f1-7c7835faa489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Other data files explored here\n",
        "yelp_data = \"data/datasets/sentiment labelled sentences/yelp_labelled.txt\"\n",
        "yelp_df = pd.read_csv(yelp_data, sep=\"\\t\", header=None)\n",
        "amazon_data = \"data/datasets/sentiment labelled sentences/amazon_cells_labelled.txt\"\n",
        "amazon_df = pd.read_csv(amazon_data, sep=\"\\t\", header=None)\n",
        "\n",
        "display_histogram(yelp_df, \"Yelp Reviews\")\n",
        "display_histogram(amazon_df, \"Amazon Reviews\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrhH5gxhDGWN"
      },
      "source": [
        "## TASK 3: Setting BERT up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgyFw7zkDIM_"
      },
      "source": [
        "__IMPORTANT__:\n",
        "BERT uses two special tokens while tokenization, they are [CLS] and [SEP]. The [CLS] token is used to capture the overall representation of the input sequence for classification tasks, while the [SEP] token is used to indicate sentence boundaries and separate different segments of text, enabling BERT to understand relationships between sentences. These tokens play a vital role in enabling BERT to handle a wide range of natural language processing tasks effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cstsfT2B3U75"
      },
      "source": [
        "Let us now begin by understanding the Tokenizer used by BERT and the BERT Model Inputs and Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bdagkfGR3U76",
        "outputId": "cf3024e9-a0c7-47f1-96bf-86f0d9625601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "# import specific models\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "# define a max length constant\n",
        "MAX_LENGTH = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8NP_1_q3U76",
        "outputId": "e226dc85-f50b-46ee-a629-1b5b7e762b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# downloads a bunch of stuff. On our computer, this took ~half a minute\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# expect to see:\n",
        "# Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
        "# - This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
        "# - This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
        "# All the weights of TFBertModel were initialized from the PyTorch model.\n",
        "# If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dyC5gU3v-YyG",
        "outputId": "1c911d93-21dc-4bd3-9a9e-f29e59f7e614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  109482240 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109482240 (417.64 MB)\n",
            "Trainable params: 109482240 (417.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: print out a summary of your downloaded bert model\n",
        "bert.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCz4eg5x-bal"
      },
      "source": [
        "Notice how there are 109M parameters. These parameters have already been trained. We want to make sure these are not trained when we add on our own components later. (We'll \"freeze\" them.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04eD8Fa42cVy"
      },
      "source": [
        "1. What kind of text data do these weights encode? (Scour the internet and describe the contents of the data used to train BERT)\n",
        "They contain contiguous pieces of text with tokens masked at random, along with next sentence predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmIp4Rs7DVUE"
      },
      "source": [
        "## The Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze5NIO3x3U76",
        "outputId": "50ceeb80-7db1-4cb4-9f9b-3bd6ac594ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length is :  30522\n",
            "['[PAD]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]']\n",
            "['##！', '##（', '##）', '##，', '##－', '##．', '##／', '##：', '##？', '##～']\n",
            "['\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+']\n",
            "n e t w o r k\n",
            "[ S E P ]\n",
            "[ M A S K ]\n",
            "2990\n"
          ]
        }
      ],
      "source": [
        "# TODO: print out the first 10 tokens in the tokenizer's vocabulary, the\n",
        "# last ten tokens, and ten tokens from somewhere in the middle of the vocabulary\n",
        "# print out the things necessary to answer the questions below\n",
        "\n",
        "# tokenizer.vocab will access the vocabulary\n",
        "# tokenizer.vocab.keys() will give you the words in the vocabulary. You can convert this to a list to index into it.\n",
        "# tokenizer.vocab[string] will give you the token id for the string\n",
        "# tokenizer.decode(id) will give you the string for the token id\n",
        "\n",
        "print(\"Vocab length is : \",len(tokenizer.vocab))\n",
        "print(list(tokenizer.vocab.keys())[:10])\n",
        "print(list(tokenizer.vocab.keys())[-10:])\n",
        "print(list(tokenizer.vocab.keys())[1000:1010])\n",
        "print(tokenizer.decode(2897))\n",
        "print(tokenizer.decode(102))\n",
        "print(tokenizer.decode(103))\n",
        "print(tokenizer.vocab['jack'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kMBiLGYRVih"
      },
      "source": [
        "2. What is the token associated with id 2897?\n",
        "\n",
        " Network\n",
        "3. What is the token associated with id 102?\n",
        "\n",
        " [SEP]\n",
        "4. What is the token associated with id 103?\n",
        "\n",
        " [MASK]\n",
        "5. Is your name in BERT's vocabulary (make sure to used the lowercase version, e.g. \"mai\")? If yes, what is it's id?\n",
        "\n",
        " Yes! ID 2990"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahvhFZSE3U76",
        "outputId": "f88e7fc9-2fa7-42b2-ab92-63a9b186bd6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids :  tf.Tensor([[  101  7592  1010  2026  3899  2003 10140  1010  2053  2428   102]], shape=(1, 11), dtype=int32)\n",
            "token_type_ids :  tf.Tensor([[0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 11), dtype=int32)\n",
            "attention_mask :  tf.Tensor([[1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 11), dtype=int32)\n",
            "[CLS] hello, my dog is cute, no really [SEP]\n"
          ]
        }
      ],
      "source": [
        "# example of tokenizing a sentence with the bert tokenizer\n",
        "input_text = \"Hello, my dog is cute, no really\"\n",
        "out = tokenizer(input_text,return_tensors=\"tf\")\n",
        "for key in out:\n",
        "    print(key,\": \",out[key])\n",
        "\n",
        "# notice the differences between the input_text and what is printed out here\n",
        "print(tokenizer.decode(out[\"input_ids\"][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7aibPRm3U76"
      },
      "source": [
        "Notice the different keys returned by the tokenizer. The model can take as input all three keys or just one of them the \"input_ids\".\n",
        "Since the model requires a fixed length input, we will need to pad the sequences to the same length. Let us pad and turn the sequences into length 15 as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9rQN3WHF3U77",
        "outputId": "4f9acf4b-274d-47bb-eebc-41b308a1e0d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids :  tf.Tensor([[  101  7592  1010  2026  3899  2003  2025 10140  1010  2053  2428   102]], shape=(1, 12), dtype=int32)\n",
            "token_type_ids :  tf.Tensor([[0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 12), dtype=int32)\n",
            "attention_mask :  tf.Tensor([[1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 12), dtype=int32)\n",
            "[CLS] hello, my dog is not cute, no really [SEP]\n"
          ]
        }
      ],
      "source": [
        "# TODO: set the max_length and truncation parameters of the tokenizer\n",
        "# the behavior that you want to end up with is a tokenizer that produces tensors that\n",
        "# are never over 15. You are not providing paired input\n",
        "\n",
        "# Tokenizer documentation: https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
        "\n",
        "input_text = \"Hello, my dog is not cute, no really\"\n",
        "\n",
        "# TODO: update this line\n",
        "out = tokenizer(input_text,return_tensors=\"tf\", max_length=15, truncation=True)\n",
        "\n",
        "\n",
        "for key in out:\n",
        "    print(key,\": \",out[key])\n",
        "print(tokenizer.decode(out[\"input_ids\"][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb7Jhkmh3U77"
      },
      "source": [
        "The tokenzier also returns multiple outputs for multiple sentences. This is useful for batching.\n",
        "\n",
        "NOTE : The max length is 512 for BERT. We will use 128 or 256 for this lab (our `MAX_LENGTH` parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VybL0aDS3U77",
        "outputId": "10bfc5f2-601a-433f-9a51-71cce292c604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids :  (3, 19)\n",
            "token_type_ids :  (3, 19)\n",
            "attention_mask :  (3, 19)\n"
          ]
        }
      ],
      "source": [
        "# TODO: make a list of sentences that you want to tokenize with at least 3 sentences that are padded to MAX_LENGTH\n",
        "# make sure that you can tokenize them all at once by looking at the shapes of the tensors that have been output\n",
        "\n",
        "setences = [\"I get knocked down, but I get up again.\",\n",
        "            \"You ain't never going to keep me down.\",\n",
        "            \"He drink's a whiskey drink, he drink's a lager drink.\"]\n",
        "\n",
        "batch_x = tokenizer(setences, return_tensors=\"tf\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "\n",
        "# here's some code to look at the shapes of the tensors that have been output\n",
        "for key in batch_x:\n",
        "    print(key,\": \",batch_x[key].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FqoZW31r3U77",
        "outputId": "c7af4b2c-2aac-4d9f-d759-b2d55e151724",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# run bert on the input_ids\n",
        "out = bert(batch_x[\"input_ids\"])\n",
        "\n",
        "# display what the keys are for us\n",
        "out.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "auI7ybZq3U77",
        "outputId": "5d69447a-a018-443e-cab2-86027a2cde38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 19, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# take a look at the shape of the last_hidden_state\n",
        "out['last_hidden_state'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZIJGjHL3U77"
      },
      "source": [
        "The model returns two tensors of interest. One is the pooled output and the other is contextual hidden state over every token. We will use the hidden state associated with the first token [CLS] for classification. Additional strategies involve averaging the non padding states. The pooler output is a summary of the hidden states.\n",
        "\n",
        "5. Investigate the shape of `last_hidden_state`. What is the __meaning__ of each dimension? (why are each dimension numbered as they are/what do they correspond to?)\n",
        "\n",
        " batch_size=3 sequence_length=19 hidden_size=768"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8-nEKeH13U77",
        "outputId": "03510e5f-a3a5-4e95-8a94-8ce90b846a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First token [CLS] :\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 768), dtype=float32, numpy=\n",
              "array([[-0.53374213,  0.09301402,  0.27630973, ..., -0.02173516,\n",
              "         0.7626597 ,  0.10481489],\n",
              "       [-0.29467353, -0.08910201,  0.18818626, ..., -0.35127914,\n",
              "         0.66208184,  0.24161315],\n",
              "       [-0.43774474,  0.47126353,  0.2655784 , ..., -0.5121259 ,\n",
              "         0.8407952 ,  0.19904281]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# we can also run bert with unpacked inputs\n",
        "out = bert(**batch_x)\n",
        "\n",
        "# or with them as \"input_ids\" explicitly\n",
        "out = bert(input_ids=batch_x[\"input_ids\"])\n",
        "\n",
        "print(\"First token [CLS] :\")\n",
        "out[\"last_hidden_state\"][:,0,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDOKY_s6B8Ie"
      },
      "source": [
        "## Create a Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Op6JBjoM3U78"
      },
      "outputs": [],
      "source": [
        "# define a batch size for our experiments\n",
        "BATCH_SIZE = 4\n",
        "# define a percentage of the data to use for training\n",
        "SPLIT_PC = .80\n",
        "\n",
        "# TODO: caluculate the last index for the training data\n",
        "END = len(imdb_df) * SPLIT_PC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QlTlTs_SRVit",
        "outputId": "e2b6d187-3711-42cc-c770-148a80b0db37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(599,)\n",
            "(599,)\n",
            "(149,)\n",
            "(149,)\n"
          ]
        }
      ],
      "source": [
        "#  TODO: get the training data and testing data set up\n",
        "X_train = imdb_df.loc[:END,0]\n",
        "y_train = imdb_df.loc[:END,1]\n",
        "X_test = imdb_df.loc[END:,0]\n",
        "y_test = imdb_df.loc[END:,1]\n",
        "\n",
        "# TODO: add print statements to verify the sizes of your training/testing data are correct\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sBGgSLsK3U78"
      },
      "outputs": [],
      "source": [
        "# data generator for the model\n",
        "def data_generator(sentences: np.array,labels: np.array,batch_size: int) -> tuple: #(dict,tf.Tensor)\n",
        "    i = 0\n",
        "    while True:\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        # TODO: append batch_size number of sentences and labels to batch_x and batch_y\n",
        "        # Make sure that you don't re-use sentences and labels that you've already put into batches!\n",
        "        #YOU PROBABLY WANT A LOOP HERE\n",
        "        while len(batch_x) < batch_size:\n",
        "            batch_x.append(sentences[i])\n",
        "            batch_y.append(labels[i])\n",
        "            i = (i+1) % len(sentences)\n",
        "\n",
        "        # TODO: tokenize the batch_x, padding to MAX_LENGTH, and truncating to MAX_LENGTH\n",
        "        batch_x = tokenizer(batch_x, return_tensors=\"tf\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "        # debugging prints (make sure that these are commented out when you actually train your model)\n",
        "        # should be (batch_size, MAX_LENGTH)\n",
        "        #print(batch_x['input_ids'].shape)\n",
        "\n",
        "        # convert our ys into the appropriate tensor\n",
        "        batch_y = tf.convert_to_tensor(batch_y)\n",
        "\n",
        "        # debugging prints (make sure that these are commented out when you actually train your model)\n",
        "        # should be (batch_size,)\n",
        "        # print(batch_y.shape)\n",
        "        yield dict(batch_x), batch_y\n",
        "\n",
        "train_data = data_generator(X_train, y_train, BATCH_SIZE)\n",
        "test_data = data_generator(X_test , y_test,BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwi_HtRmCfFs"
      },
      "source": [
        "**\"Bonus\" Question** - How would you implement randomness in the generator above. (HINT `numpy.random.choice` and its `replace` option)\n",
        "\n",
        "(This is bonus in the sense that it is a good exercise to think about, not in the sense of us giving you extra credit. Feel free to talk to Prof. Mai more about the intersection of equity and extra credit.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n78JGhebB4C_"
      },
      "source": [
        "## TASK 4: Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DQjpBh_-liQ"
      },
      "source": [
        "Remember how you used concatenated embeddings for your NN model for HW5. The model we design in this lab will take as input token_ids (batch_size, embedding_dim) , run it through a non-trainable bert, extract the 768 dim vector associated with the [CLS] token of each sentence in a batch, this 768 dim vector will play the role of our concatenated embeddings. The main take away is this : Any input size up to 512 will return a 768 dim vector we can use as an embedding for the entire sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9T-oAymn3U78",
        "outputId": "4fa8dafa-2f2d-4a56-bfe8-03feae68a322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# Build the model\n",
        "# This takes < 15 sec to run on our computer\n",
        "\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased',output_attentions = False,return_dict=False)\n",
        "# we do not need attention outputs\n",
        "# we want to return tuples since they are easier to access\n",
        "\n",
        "bert_model.trainable = False\n",
        "# setting trainable to false ensures\n",
        "# we do not update its weights\n",
        "model_ = tf.keras.Sequential([\n",
        "    bert_model,\n",
        "    tf.keras.layers.Lambda(lambda x: x[0][:,0,:]), # https://keras.io/api/layers/core_layers/lambda/\n",
        "    tf.keras.layers.Dense(50,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pua8t3wRViu"
      },
      "source": [
        "1. What does the `Lambda` layer do? Why do we need it? (Read the documentation and investigate. Think carefully about what `x[0][:,0,:]` means. `x[0]` here is a numpy array.)\n",
        "\n",
        " The lambda layer extracts the hidden layer for the [CLS] token because that is commonly the first in the sequence for BERT models.\n",
        "\n",
        "2. What weights will you be training in this model?\n",
        "\n",
        " The 50 relu weights and the 1 sigmoid weight.\n",
        "3. What weights will you __not__ be training in this model?\n",
        "\n",
        " All of the BERT weights, since we set trainable to be false."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heoBiDyaBl72"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "We use `.fit` here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d_b3IWY_ZZz"
      },
      "source": [
        "We will also be adding a validation data generator and validation steps.\n",
        "This will allow us to check accuracy on the test_data wile we train over each epoch.\n",
        "\n",
        "For this part, you'll be training in some different configurations and __recording your results__. (don't forget to write these down!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O1Seudgl3U79",
        "outputId": "80a0f027-592b-4347-8bdb-3734104c4b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5b9dd329f188>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2 epochs takes ~2 and a half minutes on our computer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 2 epochs takes ~2 and a half minutes on our computer\n",
        "model_.fit(\n",
        "    train_data,\n",
        "    epochs=1,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=(len(X_train)//BATCH_SIZE) - 1,\n",
        "    validation_data=test_data,\n",
        "    validation_steps=BATCH_SIZE*4,\n",
        "    validation_batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of1cKkNACWjH"
      },
      "source": [
        "TODO: Now train the model on the other two files present in the data folder and report your results (make sure that you train your model from scratch). You will want to experiment with different `MAX_LENGTH`s, `batch_size`s, the number of dense layers you have, the number of hidden units per layer.\n",
        "\n",
        "In general, the more layers corresponds to the more levels of abstract information that your model will be able to extract/represent. The more hidden units (the \"wider\") your network has, the more information it will be able to memorize.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  TODO: get the training data and testing data set up\n",
        "X_train = yelp_df.loc[:END,0]\n",
        "y_train = yelp_df.loc[:END,1]\n",
        "X_test = yelp_df.loc[END:,0]\n",
        "y_test = yelp_df.loc[END:,1]\n",
        "\n",
        "train_data = data_generator(X_train, y_train, BATCH_SIZE)\n",
        "test_data = data_generator(X_test , y_test,BATCH_SIZE)\n",
        "\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased',output_attentions = False,return_dict=False)\n",
        "# we do not need attention outputs\n",
        "# we want to return tuples since they are easier to access\n",
        "\n",
        "bert_model.trainable = False\n",
        "# setting trainable to false ensures\n",
        "# we do not update its weights\n",
        "model_ = tf.keras.Sequential([\n",
        "    bert_model,\n",
        "    tf.keras.layers.Lambda(lambda x: x[0][:,0,:]), # https://keras.io/api/layers/core_layers/lambda/\n",
        "    tf.keras.layers.Dense(50,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "model_.fit(\n",
        "    train_data,\n",
        "    epochs=2,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=(len(X_train)//BATCH_SIZE) - 1,\n",
        "    validation_data=test_data,\n",
        "    validation_steps=BATCH_SIZE*4,\n",
        "    validation_batch_size=BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "LgIF3X0Qrhn6",
        "outputId": "fbf4c4da-276c-4046-f1c0-bdf235521c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148/148 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.8091"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-6f1332f13eec>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m model_.fit(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-2bdb6ce10187>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(sentences, labels, batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#YOU PROBABLY WANT A LOOP HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcxIDKd1RViv"
      },
      "source": [
        "I would love to answer these questions down here, but I cannot get the model to complete training, and it provides absolutely no information other than a \"Stop iteration\" error which is completely useless. I have no idea what the problem is and don't know where to even start debugging because the errors are not informative enough."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}